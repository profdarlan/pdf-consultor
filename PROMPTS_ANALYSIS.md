# üìù An√°lise de Prompts e Chain of Thought - PDF Consultor

**Data:** 2026-02-12 01:20 UTC
**Vers√£o:** 1.0.0
**Status:** ‚úÖ Funcional

---

## üéØ Resumo Executivo

| Aspecto | Status | Avalia√ß√£o |
|----------|--------|-----------|
| **Prompts de Chat** | ‚úÖ Implementado | ‚ö†Ô∏è B√°sico, pode ser melhorado |
| **Prompts de Resumo** | ‚úÖ Implementado | ‚ö†Ô∏è B√°sico, sem CoT expl√≠cito |
| **Chain of Thought** | ‚ö†Ô∏è Parcial | ‚ö†Ô∏è Implicito no contexto, n√£o estruturado |
| **RAPTOR Prompts** | ‚úÖ Implementado | ‚úÖ Adequado para clustering |
| **Consist√™ncia** | ‚ö†Ô∏è M√©dia | ‚ö†Ô∏è Prompts dispersos nos arquivos |

---

## üìä An√°lise Detalhada

### 1. Prompts de Chat (`app/chat_service.py`)

#### Prompt Atual

**Prompt System:**
```python
"Voc√™ √© um assistente especializado em responder perguntas sobre documentos."
```

**Prompt do Usu√°rio:**
```python
prompt_parts = [
    "Voc√™ √© um assistente especializado em responder perguntas sobre documentos PDF.",
    "Voc√™ deve responder baseando-se APENAS no contexto fornecido abaixo.",
    "Se a informa√ß√£o n√£o estiver no contexto, diga que n√£o encontrou a resposta.",
    "Seja claro, conciso e cite a p√°gina das informa√ß√µes quando poss√≠vel.",
    "",
    "CONTEXTO DO DOCUMENTO:",
    context,
    "",
    "HIST√ìRICO DE CONVERSA:",
    # ... hist√≥rico ...
    "PERGUNTA ATUAL:\n{query}",
    "RESPOSTA:"
]
```

#### ‚ö†Ô∏è Problemas Identificados

1. **Sem instru√ß√£o expl√≠cita de Chain of Thought**
   - O modelo n√£o √© orientado a raciocinar passo a passo
   - Gera resposta direta sem mostrar o processo

2. **Instru√ß√£o de cita√ß√£o vaga**
   - "cite a p√°gina das informa√ß√µes quando poss√≠vel"
   - N√£o especifica formato desejado (ex: `[P√°gina X]`)

3. **Sem instru√ß√µes de incerteza**
   - N√£o h√° orienta√ß√£o para quando o modelo tem baixa confian√ßa
   - Deve pedir esclarecimentos

4. **Prompt system muito gen√©rico**
   - "assistente especializado em responder perguntas"
   - Pode ser mais espec√≠fico sobre o tipo de documento

#### ‚úÖ Sugest√µes de Melhoria

**Prompt System Aprimorado:**
```python
"""Voc√™ √© um assistente especializado em analisar e responder perguntas sobre documentos jur√≠dicos, financeiros e t√©cnicos.

Sua abordagem:
1. Analise a pergunta com cuidado
2. Identifique os trechos relevantes no contexto
3. Raciocine sobre a rela√ß√£o entre os trechos e a pergunta
4. Formule uma resposta clara e precisa
5. Sempre cite a p√°gina fonte no formato [P√°gina X]
6. Se houver conflito de informa√ß√µes, mencione ambas as fontes
7. Se n√£o encontrar a resposta, diga explicitamente
8. Mantenha o tom profissional e objetivo

Restri√ß√µes:
- Baseie-se APENAS no contexto fornecido
- N√£o invente informa√ß√µes externas ao documento
- Seja conciso mas completo"""
```

**Prompt do Usu√°rio com CoT Estruturado:**
```python
prompt_parts = [
    "## CONTEXTO DO DOCUMENTO",
    "",
    f"Documento: {document_title}",
    f"Total de p√°ginas: {page_count}",
    "",
    "Trechos relevantes do documento:",
    "",
]

# Adicionar trechos com cita√ß√£o expl√≠cita
for i, chunk in enumerate(chunks, 1):
    prompt_parts.append(f"[Trecho {i} - P√°gina {chunk['page']}]")
    prompt_parts.append(chunk['text'][:500])  # Limitar tamanho
    prompt_parts.append("")

prompt_parts.extend([
    "",
    "## PERGUNTA DO USU√ÅRIO",
    f"{query}",
    "",
    "## INSTRU√á√ïES DE RESPOSTA",
    "",
    "1. **Racioc√≠nio (Chain of Thought):**",
    "   - Liste os trechos relevantes encontrados",
    "   - Explique como cada trecho responde √† pergunta",
    "   - Indique se h√° conflitos ou informa√ß√µes complementares",
    "",
    "2. **Resposta Direta:**",
    "   - Forne√ßa uma resposta clara e concisa",
    "   - Sempre cite a p√°gina no formato [P√°gina X]",
    "   - Seja objetivo e direto",
    "",
    "3. **Fontes:**",
    "   - Liste as p√°ginas utilizadas: [P√°gina X], [P√°gina Y], ...",
    "",
    "Agora, forne√ßa sua resposta no formato acima.",
])
```

---

### 2. Prompts de Resumo (`app/chat_service.py` & `app/raptor_service.py`)

#### Prompt Atual (Sumariza√ß√£o)

```python
prompt = f"""Resuma o seguinte documento de forma {detail_level}:

{combined_text}

RESUMO:"""
```

#### ‚ö†Ô∏è Problemas Identificados

1. **Sem instru√ß√µes de estrutura**
   - N√£o especifica como organizar o resumo
   - Pode resultar em texto desorganizado

2. **Sem instru√ß√µes de foco**
   - N√£o h√° orienta√ß√£o sobre o que priorizar
   - Pode incluir informa√ß√µes irrelevantes

3. **Sem verifica√ß√£o de qualidade**
   - N√£o pede para identificar informa√ß√µes principais vs. secund√°rias

#### ‚úÖ Sugest√µes de Melhoria

**Prompt Aprimorado:**
```python
detail_prompt_map = {
    "brief": {
        "instruction": "um resumo breve (1-2 par√°grafos, m√°ximo 150 palavras)",
        "structure": "Tema principal + pontos-chave (m√°x. 5 bullets)",
        "focus": "Apenas informa√ß√µes essenciais"
    },
    "medium": {
        "instruction": "um resumo detalhado (3-5 par√°grafos, m√°ximo 300 palavras)",
        "structure": "Introdu√ß√£o + desenvolvimento + conclus√£o (com se√ß√µes numeradas)",
        "focus": "Informa√ß√µes principais com contexto suficiente"
    },
    "detailed": {
        "instruction": "um resumo completo e abrangente (500-700 palavras)",
        "structure": "T√≠tulo + se√ß√µes tem√°ticas + conclus√£o + pontos-chave destacados",
        "focus": "Todas as informa√ß√µes relevantes, incluindo detalhes espec√≠ficos"
    }
}

detail_config = detail_prompt_map[detail_level]

prompt = f"""Voc√™ √© um assistente especializado em criar resumos estruturados de documentos.

### Tarefa
Crie um resumo do documento abaixo seguindo estas instru√ß√µes:

**N√≠vel de Detalhe:** {detail_config['instruction']}
**Estrutura Exigida:** {detail_config['structure']}
**Foco:** {detail_config['focus']}

### Conte√∫do do Documento
{combined_text}

### Formato da Resposta
Use o seguinte formato:

# RESUMO: {document_title}

## Tema Principal
[1-2 frases descrevendo o assunto central do documento]

## {Estrutura conforme n√≠vel escolhido}

[Desenvolva o resumo aqui seguindo a estrutura especificada]

## Pontos-Chave
‚Ä¢ [Ponto 1]
‚Ä¢ [Ponto 2]
‚Ä¢ [Ponto 3]
...

---

RESUMO:"""
```

---

### 3. Prompts RAPTOR (`app/raptor_service.py`)

#### Prompt Atual

```python
prompt = f"""Voc√™ √© um assistente especializado em resumir documentos.

{context}

Abaixo est√£o trechos de um documento que devem ser resumidos em um √∫nico par√°grafo coeso:

{combined_text}

RESUMO:"""
```

#### ‚ö†Ô∏è Problemas Identificados

1. **Contexto n√£o utilizado**
   - `{context}` √© definido mas raramente preenchido
   - Perde oportunidade de passar contexto de cluster anterior

2. **Sem instru√ß√µes de coes√£o**
   - "√∫nico par√°grafo coeso" √© vago
   - N√£o especifica como conectar ideias

3. **Preso a um par√°grafo**
   - Para resumos de m√∫ltiplos chunks, um par√°grafo pode ser insuficiente

#### ‚úÖ Sugest√µes de Melhoria

**Prompt Aprimorado:**
```python
def summarize_chunk_group(self, chunks: List[str], context: str = "", level: int = 1) -> str:
    """
    Prompt aprimorado para RAPTOR com CoT
    """

    # Descrever o n√≠vel para contexto
    level_description = {
        1: "primeiro n√≠vel de s√≠ntese (agrupando trechos relacionados)",
        2: "segundo n√≠vel de s√≠ntese (criando temas abstratos)",
        3: "terceiro n√≠vel de s√≠ntese (desenvolvendo conceitos de alto n√≠vel)"
    }

    combined_text = "\n\n".join([
        f"[Trecho {i+1}] {chunk}"
        for i, chunk in enumerate(chunks)
    ])

    prompt = f"""Voc√™ √© um assistente especializado em criar s√≠nteses hier√°rquicas de documentos.

### Contexto
{context}

### Tarefa
Crie uma s√≠ntese dos trechos abaixo no n√≠vel {level}: {level_description[level]}

### Conte√∫do
{combined_text}

### Instru√ß√µes
1. Identifique os temas comuns entre os trechos
2. Agrupe informa√ß√µes relacionadas
3. Sintetize em uma resposta coesa
4. Mantenha o n√≠vel de abstra√ß√£o apropriado
5. Preserve as informa√ß√µes essenciais

### Formato da Resposta
[S√çNTESE N√çVEL {level}]

[Tema Central: ...]

[S√≠ntese em 2-3 frases conectadas]

---

RESUMO:"""

    # ... chamada ao LLM ...
```

---

### 4. Chain of Thought (CoT) - Situa√ß√£o Atual

#### Status: ‚ö†Ô∏è Implicito, n√£o Estruturado

O sistema **N√ÉO implementa Chain of Thought expl√≠cito**. O racioc√≠nio √©:

1. **Impl√≠cito no prompt** - instru√ß√£o geral para raciocinar
2. **Dependente do LLM** - modelo decide se mostrar racioc√≠nio
3. **Sem estrutura definida** - n√£o h√° formato fixo para CoT

#### Como Funciona Atualmente

```python
# chat_service.py - build_prompt()

prompt = """Voc√™ √© um assistente especializado em responder perguntas sobre documentos PDF.
Voc√™ deve responder baseando-se APENAS no contexto fornecido abaixo.
Se a informa√ß√£o n√£o estiver no contexto, diga que n√£o encontrou a resposta.
Seja claro, conciso e cite a p√°gina das informa√ß√µes quando poss√≠vel.

CONTEXTO DO DOCUMENTO:
{context}

PERGUNTA ATUAL:
{query}

RESPOSTA:"""
```

#### Por que CoT N√£o √© Expl√≠cito

1. **RAG j√° filtra contexto**
   - RAG seleciona apenas chunks relevantes
   - CoT expl√≠cito pode ser redundante

2. **Lat√™ncia**
   - CoT estruturado aumenta tempo de resposta
   - Tokens adicionais para racioc√≠nio

3. **Custo**
   - CoT usa mais tokens do LLM
   - Aumenta custo de API

---

## üöÄ Recomenda√ß√µes de Melhoria

### Prioridade Alta

#### 1. Implementar CoT Estruturado (Opcional)

```python
# Novo m√©todo em chat_service.py

def build_cot_prompt(self, query: str, context: str, history: List[ChatMessage]) -> dict:
    """
    Gera prompts separados para racioc√≠nio e resposta
    """

    cot_prompt = """Analise a pergunta e o contexto fornecido.

Pergunta: {query}

Trechos do Documento:
{context}

Instru√ß√µes:
1. Identifique os trechos relevantes para responder √† pergunta
2. Explique como cada trecho se relaciona com a pergunta
3. Note se h√° informa√ß√µes conflitantes
4. Liste as fontes utilizadas

Responda em formato estruturado:
[RACIOC√çNIO]
[Trechos Identificados]
- Trecho X (P√°gina Y): [rela√ß√£o com a pergunta]

[Conclus√£o]
[Resposta preliminar baseada nos trechos]
"""

    answer_prompt = """Com base no seu racioc√≠nio anterior, forne√ßa uma resposta direta ao usu√°rio.

Pergunta: {query}

Formato:
[RESPOSTA]
[Resposta clara e concisa]
[Fontes: P√°gina X, P√°gina Y, ...]
"""

    return {
        "cot": cot_prompt,
        "answer": answer_prompt
    }
```

**Uso:**
```python
def chat_with_cot(self, query: str, document_id: str, history: List[ChatMessage]):
    # 1. Gerar prompts separados
    prompts = self.build_cot_prompt(query, context, history)

    # 2. Primeira chamada - Racioc√≠nio
    cot_response = self.llm_client.chat.completions.create(
        model=settings.openai_model,
        messages=[
            {"role": "system", "content": "Voc√™ √© um analista de documentos."},
            {"role": "user", "content": prompts["cot"]}
        ],
        temperature=0.1,
        max_tokens=500
    )

    # 3. Segunda chamada - Resposta final
    final_response = self.llm_client.chat.completions.create(
        model=settings.openai_model,
        messages=[
            {"role": "system", "content": cot_response.choices[0].message.content},
            {"role": "user", "content": prompts["answer"]}
        ],
        temperature=0.3,
        max_tokens=1000
    )
```

#### 2. Criar Gerenciador de Prompts Centralizado

```python
# app/prompts.py

class PromptManager:
    """Gerenciador centralizado de prompts"""

    # Prompts de Chat
    CHAT_SYSTEM = """Voc√™ √© um assistente especializado em analisar e responder perguntas sobre {doc_type}.

Sua abordagem:
1. Analise a pergunta com cuidado
2. Identifique os trechos relevantes no contexto
3. Raciocine sobre a rela√ß√£o entre os trechos e a pergunta
4. Formule uma resposta clara e precisa
5. Sempre cite a p√°gina fonte no formato [P√°gina X]
6. Se houver conflito de informa√ß√µes, mencione ambas as fontes
7. Se n√£o encontrar a resposta, diga explicitamente

Restri√ß√µes:
- Baseie-se APENAS no contexto fornecido
- N√£o invente informa√ß√µes externas ao documento
- Seja conciso mas completo"""

    CHAT_USER = """## CONTEXTO DO DOCUMENTO

Documento: {title}
Total de p√°ginas: {page_count}
Categoria: {category}

Trechos relevantes:
{chunks_formatted}

## PERGUNTA
{query}

## INSTRU√á√ïES
Forne√ßa uma resposta clara e precisa baseada nos trechos acima.
Cite sempre a p√°gina no formato [P√°gina X].

## RESPOSTA"""

    # Prompts de Resumo
    SUMMARY_BRIEF = """Resuma o documento abaixo em 1-2 par√°grafos (m√°x. 150 palavras).

Foco: Informa√ß√µes essenciais apenas.
Estrutura: Tema principal + at√© 5 bullets.

Documento:
{content}

RESUMO:"""

    SUMMARY_MEDIUM = """Resuma o documento abaixo em 3-5 par√°grafos (m√°x. 300 palavras).

Estrutura: Introdu√ß√£o + desenvolvimento + conclus√£o (com se√ß√µes numeradas).
Foco: Informa√ß√µes principais com contexto suficiente.

Documento:
{content}

RESUMO:"""

    SUMMARY_DETAILED = """Resuma o documento abaixo de forma completa (500-700 palavras).

Estrutura: T√≠tulo + se√ß√µes tem√°ticas + conclus√£o + pontos-chave destacados.
Foco: Todas as informa√ß√µes relevantes, incluindo detalhes espec√≠ficos.

Documento:
{content}

RESUMO:"""

    # Prompts RAPTOR
    RAPTOR_LEVEL_1 = """Sintetize os trechos abaixo no primeiro n√≠vel de abstra√ß√£o.

Contexto: {context}

Trechos:
{chunks}

Instru√ß√µes:
- Identifique temas comuns
- Agrupe informa√ß√µes relacionadas
- Sintetize em 2-3 frases conectadas

S√çNTESE N√çVEL 1:"""

    RAPTOR_LEVEL_2 = """Sintetize os trechos abaixo no segundo n√≠vel de abstra√ß√£o.

Contexto: {context}

Resumos anteriores:
{previous_summaries}

Instru√ß√µes:
- Desenvolva conceitos de alto n√≠vel
- Mantenha coes√£o entre resumos anteriores
- Abstraia detalhes espec√≠ficos

S√çNTESE N√çVEL 2:"""

    RAPTOR_LEVEL_3 = """Sintetize os trechos abaixo no terceiro n√≠vel de abstra√ß√£o (resumo executivo).

Contexto: {context}

Resumos anteriores:
{previous_summaries}

Instru√ß√µes:
- Desenvolva conceitos executivos
- Capture o essencial do documento
- Apresente como resumo executivo

RESUMO EXECUTIVO:"""

    @classmethod
    def get_chat_prompt(cls, doc_type="jur√≠dico", **kwargs):
        """Retorna prompt formatado de chat"""
        return cls.CHAT_SYSTEM.format(doc_type=doc_type), cls.CHAT_USER.format(**kwargs)

    @classmethod
    def get_summary_prompt(cls, level="medium", **kwargs):
        """Retorna prompt formatado de resumo"""
        prompt_map = {
            "brief": cls.SUMMARY_BRIEF,
            "medium": cls.SUMMARY_MEDIUM,
            "detailed": cls.SUMMARY_DETAILED
        }
        return prompt_map[level].format(**kwargs)

    @classmethod
    def get_raptor_prompt(cls, level=1, **kwargs):
        """Retorna prompt formatado de RAPTOR"""
        prompt_map = {
            1: cls.RAPTOR_LEVEL_1,
            2: cls.RAPTOR_LEVEL_2,
            3: cls.RAPTOR_LEVEL_3
        }
        return prompt_map[level].format(**kwargs)
```

---

### Prioridade M√©dia

#### 3. Adicionar Prompt de Instru√ß√µes por Categoria

```python
# app/prompts.py

PROMPTS_BY_CATEGORY = {
    "juridico": """Voc√™ √© um assistente especializado em an√°lise jur√≠dica.

Foco:
- Identificar fundamenta√ß√£o legal
- Notificar precedentes jurisprudenciais
- Analisar argumentos e contra-argumentos
- Citar dispositivos legais quando aplic√°vel

Tom: Formal, preciso e t√©cnico.""",

    "financeiro": """Voc√™ √© um assistente especializado em an√°lise financeira.

Foco:
- Identificar dados num√©ricos e tend√™ncias
- Analisar indicadores financeiros
- Notificar per√≠odos e prazos
- Calcular totais e compara√ß√µes quando aplic√°vel

Tom: Objetivo, anal√≠tico e detalhado.""",

    "tecnico": """Voc√™ √© um assistente especializado em an√°lise t√©cnica.

Foco:
- Identificar especifica√ß√µes t√©cnicas
- Analisar procedimentos e processos
- Notificar conformidades e padr√µes
- Explicar termos t√©cnicos quando necess√°rio

Tom: Esclarecedor, estruturado e educativo.""",

    "outros": """Voc√™ √© um assistente especializado em an√°lise de documentos.

Foco:
- Identificar informa√ß√µes principais
- Sintetizar pontos-chave
- Clarificar ambiguidades
- Organizar informa√ß√µes logicamente

Tom: Claro, profissional e adapt√°vel."""
}
```

#### 4. Adicionar Valida√ß√£o de Resposta

```python
# app/chat_service.py

def validate_response(self, response: str, query: str, chunks: List[dict]) -> dict:
    """
    Valida se a resposta cont√©m as fontes citadas
    """
    issues = []

    # Verifica se cita p√°ginas
    if "[P√°gina" not in response and "p√°gina" not in response.lower():
        issues.append("Resposta n√£o cita p√°ginas do documento")

    # Verifica se responde √† pergunta
    if len(response) < 50:
        issues.append("Resposta muito curta")

    # Verifica se usa apenas contexto
    # (simplificado - em produ√ß√£o seria mais complexo)

    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "warnings": []  # Avisos n√£o-cr√≠ticos
    }
```

---

### Prioridade Baixa

#### 5. Adicionar Exemplos de Few-Shot nos Prompts

```python
# Prompts com exemplos para melhor performance

CHAT_WITH_EXAMPLES = """Voc√™ √© um assistente especializado em responder perguntas sobre documentos.

Exemplo de resposta correta:

USU√ÅRIO: Qual √© o valor total do contrato?

CONTEXTO:
[P√°gina 3] O valor do contrato √© de R$ 50.000,00, conforme cl√°usula 2.1.
[P√°gina 5] Considerando adicional de 10%, o valor final √© R$ 55.000,00.

ASSISTENTE: [RACIOC√çNIO]
- O contrato estabelece um valor base de R$ 50.000,00 (P√°gina 3)
- H√° um adicional de 10% mencionado na P√°gina 5
- Valor adicional: 10% de R$ 50.000,00 = R$ 5.000,00
- Valor final: R$ 50.000,00 + R$ 5.000,00 = R$ 55.000,00

[RESPOSTA]
O valor total do contrato √© de R$ 55.000,00 (P√°gina 5), composto pelo valor base de R$ 50.000,00 (P√°gina 3) acrescido de adicional de 10%.

---

Agora, responda √† pergunta do usu√°rio seguindo o mesmo padr√£o.

CONTEXTO:
{context}

PERGUNTA:
{query}

RESPOSTA:"""
```

---

## üìä Compara√ß√£o: Atual vs. Melhorias

| Aspecto | Atual | Com Melhorias |
|----------|--------|--------------|
| **Estrutura de Prompts** | Disperso nos arquivos | Centralizado em `prompts.py` |
| **CoT Expl√≠cito** | ‚ùå N√£o implementado | ‚úÖ Opcional via `build_cot_prompt()` |
| **Instru√ß√µes Espec√≠ficas** | ‚ö†Ô∏è Gen√©ricas | ‚úÖ Por categoria e n√≠vel |
| **Few-Shot Learning** | ‚ùå N√£o implementado | ‚úÖ Exemplos nos prompts |
| **Valida√ß√£o de Resposta** | ‚ùå N√£o implementado | ‚úÖ `validate_response()` |
| **Formato de Cita√ß√µes** | Vago | ‚úÖ Padronizado `[P√°gina X]` |
| **Contexto de Categoria** | ‚ùå N√£o utilizado | ‚úÖ System prompt adaptado |

---

## üéØ Conclus√£o

### Status Atual: ‚ö†Ô∏è Funcional mas Pode ser Melhorado

**Pontos Fortes:**
- ‚úÖ Sistema funcional e operacional
- ‚úÖ RAG e RAPTOR implementados
- ‚úÖ Busca h√≠brida eficiente

**Pontos Fracos:**
- ‚ö†Ô∏è Prompts b√°sicos e gen√©ricos
- ‚ö†Ô∏è Sem CoT estruturado
- ‚ö†Ô∏è Pouca personaliza√ß√£o por categoria
- ‚ö†Ô∏è Instru√ß√µes de cita√ß√£o vagas

### Recomenda√ß√£o Principal

**Implementar um gerenciador de prompts centralizado** (`app/prompts.py`) que:

1. Centralize todos os prompts
2. Permita personaliza√ß√£o por categoria
3. Suporte CoT opcional
4. Inclua exemplos few-shot
5. Valide respostas geradas

### Impacto Estimado

| M√©trica | Atual | Com Melhorias |
|----------|--------|--------------|
| Qualidade das respostas | 7/10 | 9/10 |
| Precis√£o de cita√ß√µes | 6/10 | 9/10 |
| Coer√™ncia do CoT | N/A | 8/10 |
| Custo (tokens) | Base | +20-30% |
| Lat√™ncia | Base | +10-20% |

**Decis√£o:** Implementar melhorias gradualmente, come√ßando pelo PromptManager centralizado.

---

**Documento criado:** 2026-02-12 01:20 UTC
**Pr√≥xima revis√£o:** Ap√≥s implementar PromptManager
